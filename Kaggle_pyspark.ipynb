{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_pyspark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AMEX Kaggle Competetion"
      ],
      "metadata": {
        "id": "QSKu7sCDnxuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Fecthing"
      ],
      "metadata": {
        "id": "7FSiUfIen5ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the virtual Enviroment \n",
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "i8HjqMi3mPeE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the kaggle API json file by \n",
        "#1. Go to your account, Scroll to API section and Click Expire API Token to remove previous tokens\n",
        "#2. Click on Create New API Token - It will download kaggle.json file on your machine.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "9mBjElmDmRBO",
        "outputId": "5d5af9af-fb69-4dde-b2d3-6f3dc1106243"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e496c726-dd3e-4f45-8ac4-f3ad63a4e722\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e496c726-dd3e-4f45-8ac4-f3ad63a4e722\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"shijiemao\",\"key\":\"229b59052239087c849d1ab667e93913\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the data from kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZdCzJymcxW",
        "outputId": "74b8ad29-b0ec-442b-e7ca-fd10b6f3e6b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "victorsoeiro/netflix-tv-shows-and-movies                           Netflix TV Shows and Movies                           2MB  2022-05-15 00:01:23          15241        444  1.0              \n",
            "ruchi798/data-science-job-salaries                                 Data Science Job Salaries                             7KB  2022-06-15 08:59:12           3839        138  1.0              \n",
            "zusmani/petrolgas-prices-worldwide                                 Petrol/Gas Prices Worldwide                          10KB  2022-06-24 01:25:33           1839         88  1.0              \n",
            "imoore/age-dataset                                                 Age dataset: life, work, and death of 1.22M people   34MB  2022-06-07 08:56:52           2653        103  1.0              \n",
            "ramjasmaurya/1-gb-internet-price                                   Internet Prices around 200+ countries in 2022.       12KB  2022-07-04 10:54:33            732         30  1.0              \n",
            "surajjha101/bigbasket-entire-product-list-28k-datapoints           BigBasket Entire Product List (~28K datapoints)       6MB  2022-06-22 12:51:18           1158         62  1.0              \n",
            "sameepvani/nasa-nearest-earth-objects                              NASA - Nearest Earth Objects                          7MB  2022-06-17 02:32:18           1891         86  1.0              \n",
            "devansodariya/student-performance-data                             Student Performance Dataset                           7KB  2022-05-26 13:55:09           8896        234  0.9705882        \n",
            "jimschacko/airlines-dataset-to-predict-a-delay                     Airlines Dataset to predict a delay                   6MB  2022-06-21 05:45:44           1629         43  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                              Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24          90716       1106  0.7058824        \n",
            "deepcontractor/car-price-prediction-challenge                      Car Price Prediction Challenge                      429KB  2022-07-06 11:38:32            354         33  0.9411765        \n",
            "iamsouravbanerjee/nifty500-stocks-dataset                          Stock Market Dataset (NIFTY-500)                     35KB  2022-07-11 12:16:28            433         38  1.0              \n",
            "azminetoushikwasi/ott-video-streaming-platforms-revenue-and-users  OTT, Video Streaming Platforms - Revenue and Users   11KB  2022-07-01 08:30:57            655         29  1.0              \n",
            "datasnaek/youtube-new                                              Trending YouTube Video Statistics                   201MB  2019-06-03 00:56:47         178853       4591  0.7941176        \n",
            "zynicide/wine-reviews                                              Wine Reviews                                         51MB  2017-11-27 17:08:04         162811       3335  0.7941176        \n",
            "iabhishekofficial/mobile-price-classification                      Mobile Price Classification                          71KB  2018-01-28 08:44:24          92255       1247  0.7058824        \n",
            "rtatman/188-million-us-wildfires                                   1.88 Million US Wildfires                           168MB  2020-05-12 21:03:49          20659       1016  0.8235294        \n",
            "residentmario/ramen-ratings                                        Ramen Ratings                                        40KB  2018-01-11 16:04:39          34746        792  0.7058824        \n",
            "datasnaek/chess                                                    Chess Game Dataset (Lichess)                          3MB  2017-09-04 03:09:09          30395       1017  0.8235294        \n",
            "dansbecker/powerlifting-database                                   powerlifting-database                                 9MB  2019-04-30 21:07:41           4875         59  0.5882353        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c 'amex-default-prediction'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-ffoQgUmqPL",
        "outputId": "bc9a8a65-6c47-41f8-885a-0c77523ab6c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amex-default-prediction.zip to /content\n",
            "100% 20.5G/20.5G [02:39<00:00, 109MB/s] \n",
            "100% 20.5G/20.5G [02:39<00:00, 138MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir AMEX\n",
        "! unzip amex-default-prediction.zip -d AMEX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAP0nd1bly71",
        "outputId": "f25f5a05-b0a7-466a-ade3-436f4d9929a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  amex-default-prediction.zip\n",
            "  inflating: AMEX/sample_submission.csv  \n",
            "  inflating: AMEX/test_data.csv      \n",
            "  inflating: AMEX/train_data.csv     \n",
            "  inflating: AMEX/train_labels.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm amex-default-prediction.zip"
      ],
      "metadata": {
        "id": "XklCPw2OuFis"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark session"
      ],
      "metadata": {
        "id": "u5k0UzPRsB5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession, types\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPWr7uGnsJTv",
        "outputId": "144d3e0c-e7cc-42ca-b266-1477cc059c34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 43 kB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 62.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"../content/AMEX/test_data.csv\"\n",
        "train_path = \"../content/AMEX/train_data.csv\"\n",
        "label_path = \"../content/AMEX/train_labels.csv\""
      ],
      "metadata": {
        "id": "L5zZQpBQsjvk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_path, nrows=100)\n",
        "test_df = pd.read_csv(test_path, nrows=100)\n",
        "label_df = pd.read_csv(label_path, nrows=100)"
      ],
      "metadata": {
        "id": "l3mBk5kks7yF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train types\n",
        "train_types = train_df.dtypes\n",
        "train_types_count = train_types.value_counts()\n",
        "\n",
        "## Test types\n",
        "test_types = test_df.dtypes\n",
        "test_types_count = test_types.value_counts()\n",
        "\n",
        "## Label types\n",
        "label_types = label_df.dtypes\n",
        "label_types_count = label_types.value_counts()"
      ],
      "metadata": {
        "id": "SsWXD5jPs_VE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_splits(*msg):\n",
        "    for m in msg:\n",
        "        print(m)\n",
        "        print()\n",
        "        \n",
        "print_splits(train_types_count, test_types_count, label_types_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-H9robxtVfX",
        "outputId": "29975ce7-fe60-4c02-a6f6-184ee0a4bc56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64    185\n",
            "object       4\n",
            "int64        1\n",
            "dtype: int64\n",
            "\n",
            "float64    185\n",
            "object       4\n",
            "int64        1\n",
            "dtype: int64\n",
            "\n",
            "object    1\n",
            "int64     1\n",
            "dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Types mapper\n",
        "types_map = {\n",
        "    \"object\": types.StringType(),\n",
        "    \"float64\": types.FloatType(),\n",
        "    \"int64\": types.IntegerType(),\n",
        "}\n",
        "\n",
        "# Known dtypes\n",
        "string_dtypes = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
        "date_dtypes = ['S_2']"
      ],
      "metadata": {
        "id": "_022j2WVvk9G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spark_schema(series):\n",
        "    fields = []\n",
        "    \n",
        "    for index, value in series.items():\n",
        "        if index in string_dtypes:\n",
        "            field = types.StructField(index, types.StringType(), True)\n",
        "            \n",
        "        elif index in date_dtypes:\n",
        "            field = types.StructField(index, types.DateType(), True)\n",
        "        \n",
        "        else:\n",
        "            field = types.StructField(index, types_map.get(str(value)), True)\n",
        "            \n",
        "        fields.append(field)\n",
        "    return types.StructType(fields)"
      ],
      "metadata": {
        "id": "aKw1T7ggvnwt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_schema = create_spark_schema(train_types) \n",
        "test_schema = create_spark_schema(test_types)\n",
        "label_schema = create_spark_schema(label_types)"
      ],
      "metadata": {
        "id": "jSHK9P7kvp9B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set header to True or else it will be included as row\n",
        "train_psdf = spark.read.option(\"header\", \"true\").csv(train_path, schema=train_schema)\n",
        "test_psdf = spark.read.option(\"header\", \"true\").csv(test_path, schema=test_schema)\n",
        "label_psdf = spark.read.option(\"header\", \"true\").csv(label_path, schema=label_schema)"
      ],
      "metadata": {
        "id": "kM06c6hmvrpG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check schema\n",
        "print_splits(train_psdf.schema[:3], test_psdf.schema[:3], label_psdf.schema[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4IH7XySvtxl",
        "outputId": "2a4ffc15-857b-479c-9bf3-282e646f1f10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructType([StructField('customer_ID', StringType(), True), StructField('S_2', DateType(), True), StructField('P_2', FloatType(), True)])\n",
            "\n",
            "StructType([StructField('customer_ID', StringType(), True), StructField('S_2', DateType(), True), StructField('P_2', FloatType(), True)])\n",
            "\n",
            "StructType([StructField('customer_ID', StringType(), True), StructField('target', IntegerType(), True)])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_psdf.write.parquet(\"train_amex\")\n",
        "test_psdf.write.parquet(\"test_amex\")\n",
        "label_psdf.write.parquet(\"label_amex\")"
      ],
      "metadata": {
        "id": "xeL-b71svwJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "s2Lz68bBpRcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import multiprocessing\n",
        "import re\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyspark.pandas as ps\n",
        "from pyspark import StorageLevel\n",
        "from pyspark.sql import SparkSession, types\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# SESSION PARAMETER\n",
        "CORES = multiprocessing.cpu_count()\n",
        "MAX_PARTITION_SIZE = \"134217728b\""
      ],
      "metadata": {
        "id": "JVanhlktza03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (SparkSession.builder.master(f\"local[{CORES}]\")\n",
        "                             .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
        "                             .config(\"spark.memory.offHeap.size\",\"5g\")\n",
        "                             .config(\"spark.sql.shuffle.partitions\", CORES * 3)\n",
        "                             .config(\"spark.default.parallelism\", CORES * 3)\n",
        "                             .config(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", MAX_PARTITION_SIZE)\n",
        "                             .appName(\"ML_spark\")\n",
        "                             .getOrCreate())"
      ],
      "metadata": {
        "id": "o2pcj3CYwvZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"../content/train_amex\"\n",
        "test_path = \"../content/test_amex\"\n",
        "label_path = \"../content/label_amex\""
      ],
      "metadata": {
        "id": "Afyl3GWVwvPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_df = spark.read.parquet(train_path)\n",
        "test_df = spark.read.parquet(test_path)\n",
        "label_df = spark.read.parquet(label_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTFSodtm5RKO",
        "outputId": "e422f906-692e-4ca0-9dd4-3f6521730c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.06 ms, sys: 1.41 ms, total: 10.5 ms\n",
            "Wall time: 851 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.select(\"customer_ID\").explain()  # select one column to simplify the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6CoJHMJ5m-A",
        "outputId": "33b718bb-883f-4eae-e5fa-7afa71af975f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [customer_ID#1908] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/train_amex], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<customer_ID:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_null_count(sql_df, colname):\n",
        "    count = (sql_df.select(colname)\n",
        "                   .filter(F.col(colname).isNull())\n",
        "                   .count())\n",
        "    return count"
      ],
      "metadata": {
        "id": "02BuEdJS6E_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_customer_train = get_null_count(train_df, \"customer_ID\") \n",
        "missing_customer_test = get_null_count(test_df, \"customer_ID\")\n",
        "\n",
        "total_miss = missing_customer_train + missing_customer_test\n",
        "print(f\"Missing customer_ID: {total_miss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWtUrGRR6KPe",
        "outputId": "e47fa132-4c25-4644-f511-b236d2b74190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing customer_ID: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "CjLC2Nq3os7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Known Columns\n",
        "info_cols = ['customer_ID', 'S_2']\n",
        "target_cols = ['target']\n",
        "cat_cols = [\n",
        "    'B_30', 'B_38', \n",
        "    'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
        "\n",
        "\n",
        "# Define Numeric Columns\n",
        "excluded = info_cols + cat_cols\n",
        "num_cols = [col for col in train_df.columns if col not in excluded]\n",
        "\n",
        "# Define Feature Columns\n",
        "features_cols =  cat_cols + num_cols\n",
        "\n",
        "print(f\"Number of categoric cols: {len(cat_cols)}\")\n",
        "print(f\"Number of numeric cols: {len(num_cols)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS-1L4qtW8al",
        "outputId": "4f03ea92-276c-47d6-9540-9b2e8acfb458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categoric cols: 11\n",
            "Number of numeric cols: 177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = (train_df.fillna(0, subset=num_cols)\n",
        "                    .fillna(\"null\", subset=cat_cols))\n",
        "\n",
        "test_df = (test_df.fillna(0, subset=num_cols)\n",
        "                  .fillna(\"null\", subset=cat_cols))"
      ],
      "metadata": {
        "id": "inqSvrsAXO5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_suffix(names, suffix):\n",
        "    return [name + suffix for name in names]\n",
        "    \n",
        "# Create columns aliases\n",
        "cat_index_cols = add_suffix(cat_cols, \"_index\")\n",
        "\n",
        "# Fit StringIndexer\n",
        "indexers = StringIndexer(inputCols=cat_cols, outputCols=cat_index_cols)\n",
        "indexers_model = indexers.fit(train_df)\n",
        "\n",
        "# Transform to data\n",
        "train_df_indexed = indexers_model.transform(train_df)\n",
        "test_df_indexed = indexers_model.transform(test_df)"
      ],
      "metadata": {
        "id": "eyaF0WzXXUdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See what columns the indexer handle\n",
        "indexers.getInputCols()\n",
        "\n",
        "# See the indexed columns\n",
        "train_df_indexed.select(\"B_30_index\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XMp3aoZXWry",
        "outputId": "f55c336c-0088-41b2-a64f-521063184695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|B_30_index|\n",
            "+----------+\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create columns aliases\n",
        "cat_ohe_cols = add_suffix(cat_cols, \"_ohe\")\n",
        "\n",
        "# Fit OneHotEncoder\n",
        "ohe = OneHotEncoder(inputCols=cat_index_cols, outputCols=cat_ohe_cols)\n",
        "ohe_model = ohe.fit(train_df_indexed)\n",
        "\n",
        "# Transform to data\n",
        "train_df_ohed = ohe_model.transform(train_df_indexed)\n",
        "test_df_ohed = ohe_model.transform(test_df_indexed)"
      ],
      "metadata": {
        "id": "VHDVTyV1XYln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_ohed.select(\"B_30_ohe\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj5f8xs7Xalz",
        "outputId": "537c61a0-defb-4dc3-92ec-5b1699940bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|     B_30_ohe|\n",
            "+-------------+\n",
            "|(3,[0],[1.0])|\n",
            "|(3,[0],[1.0])|\n",
            "|(3,[0],[1.0])|\n",
            "|(3,[0],[1.0])|\n",
            "|(3,[0],[1.0])|\n",
            "+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for each type\n",
        "# each tuple consist of: (function, column's suffix)\n",
        "num_funcs = [\n",
        "    (F.mean, \"_mean\"),\n",
        "    (F.stddev, \"_std\"),\n",
        "    (F.min, \"_min\"),\n",
        "    (F.max, \"_max\"),\n",
        "]\n",
        "\n",
        "cat_funcs = [\n",
        "    (F.count, \"_count\"),\n",
        "    (F.last, \"_last\"),\n",
        "    (F.countDistinct, \"_nunique\"),\n",
        "]"
      ],
      "metadata": {
        "id": "MaNd3881Xd5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arguments for .agg method\n",
        "# each arg consist of: func(colname).alias(colname + suffix)\n",
        "agg_num_args = [\n",
        "    func(col).alias(col + suffix) \n",
        "    for col, (func, suffix) in itertools.product(num_cols, num_funcs)]\n",
        "\n",
        "agg_cols_args = [\n",
        "    func(col).alias(col + suffix) \n",
        "    for col, (func, suffix) in itertools.product(cat_ohe_cols, cat_funcs)]\n",
        "\n",
        "# Combine numeric and categoric agg arguments\n",
        "agg_args = agg_num_args + agg_cols_args\n",
        "agg_args[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eE3DOHEXfuZ",
        "outputId": "15d1bee9-f26b-4ed0-8e05-42730422c9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'avg(P_2) AS P_2_mean'>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns that we won't use\n",
        "unused_cols = cat_cols + num_cols + cat_index_cols + cat_ohe_cols\n",
        "print(f\"Unused columns {len(unused_cols)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAYNtJ65XrMF",
        "outputId": "5402fe4b-e48b-43c8-8332-cefe0cffc8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unused columns 210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the agg while also dropping unused columns\n",
        "train_df_grouped = (train_df_ohed.groupBy(\"customer_ID\")\n",
        "                                 .agg(*agg_cols_args)\n",
        "                                 .drop(*unused_cols))\n",
        "\n",
        "test_df_grouped = (test_df_ohed.groupBy(\"customer_ID\")\n",
        "                                .agg(*agg_cols_args)\n",
        "                                .drop(*unused_cols))"
      ],
      "metadata": {
        "id": "HONWMYbwXues"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "kjmf_A8Mo0a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_joined_df = train_df_grouped.join(F.broadcast(label_df), on=\"customer_ID\")"
      ],
      "metadata": {
        "id": "MmQcgZeQXxX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = len(train_joined_df.columns)\n",
        "print(f\"Total features: {dim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwrto03KXz0D",
        "outputId": "b1fffe54-155c-4380-e594-72d16f32fea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total features: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "va = VectorAssembler(\n",
        "    inputCols=train_joined_df.drop(\"customer_ID\", \"target\").columns,\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"error\",\n",
        ")\n",
        "\n",
        "train_ready_df = (va.transform(train_joined_df)\n",
        "                    .select([\"customer_ID\", \"features\", \"target\"])\n",
        "                    .persist(StorageLevel.DISK_ONLY))\n",
        "\n",
        "test_ready_df = (va.transform(test_df_grouped)\n",
        "                   .select([\"customer_ID\", \"features\"])\n",
        "                   .persist(StorageLevel.DISK_ONLY))"
      ],
      "metadata": {
        "id": "UdA2RV-UX82P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "PjwbxcNpX_X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logres = LogisticRegression(featuresCol=\"features\", labelCol=\"target\")\n",
        "logres_model = logres.fit(train_ready_df)"
      ],
      "metadata": {
        "id": "kKl_Yar0YIq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbt = GBTClassifier(labelCol=\"target\", featuresCol=\"features\", maxIter=10)\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = gbt.fit(train_ready_df)"
      ],
      "metadata": {
        "id": "QQ0wsPcOd-QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "qxqHh-adYDeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = logres_model.transform(test_ready_df)\n",
        "test_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P20HxOTnYKa-",
        "outputId": "d9c93445-aab0-43b7-fc5b-71991efee6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[customer_ID: string, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_ready_df)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"probability\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"probability\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsN3vduhe0Q6",
        "outputId": "4f2994ba-679a-420c-e747-bc4632ce7099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+\n",
            "|prediction|         probability|            features|\n",
            "+----------+--------------------+--------------------+\n",
            "|       0.0|[0.69636525161398...|(66,[0,1,4,5,6,13...|\n",
            "|       0.0|[0.91370669401726...|(66,[0,1,4,5,8,13...|\n",
            "|       0.0|[0.91456496284576...|(66,[0,1,4,5,8,13...|\n",
            "|       0.0|[0.89406083609393...|(66,[0,1,4,5,6,13...|\n",
            "|       0.0|[0.92214781722093...|(66,[0,1,4,5,6,13...|\n",
            "+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c9d3a0b60ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m evaluator = MulticlassClassificationEvaluator(\n\u001b[1;32m      8\u001b[0m     labelCol=\"probability\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Error = %g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/evaluation.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column probability must be of type numeric but was actually of type struct<type:tinyint,size:int,indices:array<int>,values:array<double>>."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More and More"
      ],
      "metadata": {
        "id": "KkRVV2Kqo2Xb"
      }
    }
  ]
}